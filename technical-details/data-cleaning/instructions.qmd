**Introduction**
The purpose of this data cleaning page was to take the JSON files created in the data-collecting step, combine and flatten the data into a singular Pandas data frame. Data cleaning was an interative process I needed to add and alter throughout the Project. Once the Pandas dataframe was build, i needed to remove parts of the dataset, and create additional calculated fields that would be used in the EDA, supervised, and unsupervised learning sections.This final data frame was then saved as a csv file for both documentation and later use in the EDA step. 


**Process**
The raw JSON file consists of multi-level nested dictionaries and lists. To flatten these into a dataframe, I used Python.

Once the JSON files had been combined, the shape was (50825, 23). 8662 unique player IDs across 6388 game were captured which is still robust despite my limitations.

I first looked at the data types.
Data types were object, int64, and float 64. 
Time fields game_length and time_eliminated being float was acceptable as time was measured in seconds.

Missing data was identified using this code line:
dfRaw.notnull().mean() * 100 
Which provided how many of a fields data was null. 

My result was 100% except for the field augments which was 0. As augments had no data, it was removed.
This was likely due an error on the data-collection process. I was unable to resolve this due to the Riot API having no data to pull when I reran due to the release of Build 16. The rest of my fields had no null values.

Outlier Detection and Treatment and Normalization and Scaling were not performed at this time. I wanted my final cleaned dataset to not alter the data that exists. Instead, looking at outliers, normalization, scaling, skew and kurtosis are evaluated in the EDA section, and then performed during the modeling section. 

The final dataset was saved as csv file for usage in EDA, unsupervised and supervised learning sections.


