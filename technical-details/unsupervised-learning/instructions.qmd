# Introduction:
In this section, I will be using awnsering the following data science questions:
What are meta comps among top level TFT player boards?
What are meta comps among players who place top 4?

Champions in TFT have unique abilites and share types. A basic strategy is composing a team of unit that share traits because of bonuses given to units that share traits. For example, in Set 15, Ahiri and Jinx are both Star Guardians. When they are on the board together, they each get a unique bonus. The more Star Guardians are on the board, the greater the bonus. This aims to find common team comps at top level play. 

# Methods
Originally, I tried HDBSCAN, but realized I had used distance = Euclidean. As my data was purley categorical, euclidean distance results would be useless. When I switched to Jaccard distance, the results were poor. Which made me decide on using Hieracical Clustering. 

Using my cleaned dataset, I created a new binary dataset that showed how many frequency of unit appearance.

My main issue was the size of the dataset. Original shape = (32455, 63) which would cause Jupyter to take to long or outright crash. Before performing PCA, I removed duplicates as they do not improve the results and increase run time. After removing the duplicates, the shape became (10757, 63). This is about a third of what we started but it makes sense. We are only looking at the list of units a player employed without consideration of other variables such as star level, items, or auguments. Despite the games innate RNG, top players are very consistent at building top level meta comps.

After removing duplicates, I ran hierachtic clustering with Jaccard distance. Results lead to over 100 clusters which required me to perform PCA with n_components = 25. pca.explained_variance_ratio_ = 0.826.

Since PCA was performed, distance used was euclidean instead of Jaccard.

After running, I wanted to find the number of cluster relative to t.
t = 2 → clusters = 228
t = 3 → clusters = 11
t = 4 → clusters = 1
t = 5 → clusters = 1

I choose t = 3 and then wanted to look at the number 

#Methods 
Hierarchic Clustering:
  - A clustering algorithm.

HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise)
  - HDBSCAN is a clustering algorithm build upon DBSCAN. It can dynamically adapt adjust to different densities and form clusters within the data. It is best used for datasets with complex structures or varying densities because it creates a hierarchical tree of clusters that enable users to examine the data at different levels of granularity. Parameters that can be adjusted by the ende user are:
  The minimum number of points to form a cluster.
  The minimum number of samples in a neighborhood for a point to be considered a core point.

Principal Component Analysis (PCA):
  - 

TSNE
  - 

#Results Section:
Below are the sizes of the clusters which served as an indicator of usage. 

Below are the 11 clusters produced. 
The number each to name is the frequency of appearance. The higher the number, the more likely the champion appears on the comp which indicates if they are a staple or a secondary pick. 
 
===== COMP 1 =====
  Poppy: 0.95
  Jinx: 0.95
  Neeko: 0.81
  Rell: 0.75
  Kobuko: 0.72
  KSante: 0.68
  Xayah: 0.52
  Seraphine: 0.48
  Varus: 0.47
  Braum: 0.46

===== COMP 2 =====
  Garen: 0.95
  Rakan: 0.90
  Ezreal: 0.88
  Leona: 0.84
  Yuumi: 0.83
  Jayce: 0.57
  Katarina: 0.53
  Ryze: 0.31
  Malzahar: 0.29
  KSante: 0.29

===== COMP 3 =====
  Shen: 0.89
  Leona: 0.85
  Rell: 0.84
  Swain: 0.83
  XinZhao: 0.81
  Braum: 0.66
  Garen: 0.43
  Seraphine: 0.38
  TwistedFate: 0.37
  Zyra: 0.31

===== COMP 4 =====
  Samira: 0.93
  Sett: 0.92
  Volibear: 0.77
  Naafiri: 0.73
  XinZhao: 0.72
  Lux: 0.54
  Gwen: 0.48
  Braum: 0.46
  Viego: 0.40
  Shen: 0.38

===== COMP 5 =====
  DrMundo: 0.93
  Udyr: 0.91
  Sett: 0.87
  Naafiri: 0.80
  Vi: 0.71
  LeeSin: 0.71
  Braum: 0.54
  TwistedFate: 0.53
  Zyra: 0.45
  Aatrox: 0.44

===== COMP 6 =====
  Swain: 0.91
  Janna: 0.90
  Ashe: 0.85
  Vi: 0.77
  Zyra: 0.71
  KSante: 0.69
  JarvanIV: 0.67
  Braum: 0.55
  Udyr: 0.53
  LeeSin: 0.47

===== COMP 7 =====
  Janna: 0.83
  Malphite: 0.81
  Sivir: 0.60
  Ziggs: 0.57
  Shen: 0.57
  Ryze: 0.46
  JarvanIV: 0.44
  Neeko: 0.41
  KSante: 0.34
  Kennen: 0.31

===== COMP 8 =====
  Karma: 0.97
  Lucian: 0.94
  JarvanIV: 0.90
  Ryze: 0.66
  Swain: 0.51
  Aatrox: 0.49
  Senna: 0.46
  Gwen: 0.44
  Lux: 0.43
  Gangplank: 0.41

===== COMP 9 =====
  Kayle: 0.82
  Udyr: 0.79
  Zac: 0.72
  Jhin: 0.62
  Aatrox: 0.60
  Varus: 0.54
  KSante: 0.54
  LeeSin: 0.40
  Malzahar: 0.40
  Sett: 0.31

===== COMP 10 =====
  Zac: 0.64
  Darius: 0.64
  Malzahar: 0.64
  Kobuko: 0.58
  Poppy: 0.50
  Jayce: 0.46
  Aatrox: 0.37
  Rammus: 0.32
  Seraphine: 0.28
  KSante: 0.21

===== COMP 11 =====
  Aatrox: 0.75
  Ryze: 0.71
  Udyr: 0.65
  JarvanIV: 0.62
  Akali: 0.56
  Darius: 0.55
  Senna: 0.49
  Kennen: 0.49
  Kobuko: 0.44
  KSante: 0.41

### Conclusions:



### Part 1: Dimensionality Reduction

The objective of this section is to explore and demonstrate the effectiveness of PCA and t-SNE in reducing the dimensionality of complex data while preserving essential information and improving visualization.

1. **PCA (Principal Component Analysis):**
   - Apply PCA to your dataset.
   - Determine the optimal number of principal components.
   - Visualize the reduced-dimensional data.
   - Analyze and interpret the results.

2. **t-SNE (t-distributed Stochastic Neighbor Embedding):**
   - Implement t-SNE on the same dataset.
   - Experiment with different perplexity values.
   - Visualize the t-SNE output to reveal patterns and clusters.
   - Compare the results of t-SNE with those from PCA.

3. **Evaluation and Comparison:**
   - Evaluate the effectiveness of PCA and t-SNE in preserving data structure.
   - Compare the visualization capabilities of both techniques.
   - Discuss the trade-offs and scenarios where one technique may perform better than the other.

### Part 2: Clustering Methods